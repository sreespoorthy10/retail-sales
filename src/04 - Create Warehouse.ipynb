{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e85a76aa-a035-4d1f-96f1-c5b29472b48c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Use necessary catalog and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da3b2f9b-a974-4a76-a6eb-599d7007f908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG online_retail;\n",
    "CREATE SCHEMA IF NOT EXISTS gold;\n",
    "USE gold;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0236fd21-99b4-470d-9e42-5976becd1247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Read from source tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1cfb041-f612-4082-8de7-eb19809f0bc0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read source data into dataframe"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df = spark.sql(\"\"\"SELECT * FROM silver.cleaned_data\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d36cc06e-d1f8-4d4f-8b7d-959e49ea51fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64158c7b-c86e-49e9-a485-5f546d232a34",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create source view"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df.createOrReplaceTempView(\"uvw_src_cleaned_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc1547da-3798-4044-a1d8-4b64bdd8fc5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Merge Data into Target Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5009418a-8978-41f2-85b6-5746d43f03cc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Target Tables"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create Products Dimension Table (Assumption: SCD Type 1)\n",
    "CREATE TABLE IF NOT EXISTS dim_product (\n",
    "  --dim_product_id BIGINT GENERATED BY DEFAULT AS IDENTITY (START WITH 1 INCREMENT BY 1) PRIMARY KEY\n",
    "  dim_product_id BIGINT PRIMARY KEY\n",
    "  , product_code STRING\n",
    "  , product_description STRING\n",
    "  , average_unit_price DOUBLE\n",
    ")\n",
    "TBLPROPERTIES ( \n",
    "  'spark.databricks.delta.vacuum.logging.enable' = 'true'\n",
    ");\n",
    "\n",
    "-- Create Customers Dimension Table (Assumption: SCD Type 1)\n",
    "CREATE TABLE IF NOT EXISTS dim_customer (\n",
    "  --dim_customer_id BIGINT GENERATED BY DEFAULT AS IDENTITY (START WITH 1 INCREMENT BY 1) PRIMARY KEY\n",
    "  dim_customer_id BIGINT PRIMARY KEY\n",
    "  , customer_id INTEGER\n",
    "  , country STRING\n",
    ")\n",
    "TBLPROPERTIES ( \n",
    "  'spark.databricks.delta.vacuum.logging.enable' = 'true'\n",
    ");\n",
    "\n",
    "-- Create Fact Sales Table\n",
    "CREATE TABLE IF NOT EXISTS fact_sale (\n",
    "    fct_sale_id BIGINT PRIMARY KEY \n",
    "    , invoice_number STRING\n",
    "    , invoice_date TIMESTAMP\n",
    "    , dim_product_id BIGINT\n",
    "    , dim_customer_id BIGINT\n",
    "    , total_quantity INTEGER\n",
    "    , CONSTRAINT fk_product FOREIGN KEY (dim_product_id) REFERENCES dim_product\n",
    "    , CONSTRAINT fk_customer FOREIGN KEY (dim_customer_id) REFERENCES dim_customer\n",
    ")\n",
    "TBLPROPERTIES ( \n",
    "  'spark.databricks.delta.vacuum.logging.enable' = 'true'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad4ab4a-2177-44b6-9dda-a8f6df48d2a1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Vacuum table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "--VACUUM dim_product RETAIN 720 HOURS;            -- Commented out as it is not needed to run everytime\n",
    "--VACUUM dim_customer RETAIN 720 HOURS;           -- Commented out as it is not needed to run everytime\n",
    "--VACUUM fact_sale RETAIN 720 HOURS;              -- Commented out as it is not needed to run everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "223006b1-9c60-47e0-901b-4735fb7c0f64",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Merge into dim_product"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "WITH CTE_dim_product AS (\n",
    "  SELECT DISTINCT                                               -- Avoid Duplicates\n",
    "    ROW_NUMBER() OVER (ORDER BY product_code) AS dim_product_id -- Distinct row number for every product\n",
    "    , product_code\n",
    "    , MAX(product_description)      AS product_description\n",
    "    , ROUND(AVG(unit_price), 2)     AS average_unit_price       -- Multiple unit prices found for a product. Hence, taking the average. Assumption: DIM_Product is a SCD Type 1\n",
    "  FROM uvw_src_cleaned_df\n",
    "  GROUP BY product_code\n",
    ")\n",
    "\n",
    "\n",
    "MERGE INTO dim_product AS TGT\n",
    "USING CTE_dim_product AS SRC\n",
    "ON TGT.product_code = SRC.product_code                          -- Merge on product_code\n",
    "\n",
    "-- When matched on product_code, and the other columns are not matching, then update the existing row\n",
    "WHEN MATCHED                                                    \n",
    "AND TGT.product_description <> SRC.product_description\n",
    "AND TGT.average_unit_price <> SRC.average_unit_price                                                 \n",
    "THEN UPDATE SET\n",
    "TGT.product_description = SRC.product_description\n",
    ", TGT.average_unit_price = SRC.average_unit_price\n",
    "\n",
    "-- When not matched on product_code, insert the new row\n",
    "WHEN NOT MATCHED                                                 \n",
    "THEN INSERT *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9a70251-a469-4353-941d-d51b54432e93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Creating a temp view that has only the latest country for each customer\n",
    "CREATE OR REPLACE TEMP VIEW customers_country AS                  \n",
    "\n",
    "WITH ranked_customers_country AS (\n",
    "  SELECT\n",
    "    customer_id\n",
    "    , UPPER(country)                                                          AS country\n",
    "    , invoice_date\n",
    "    , ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY invoice_date DESC) AS rn             -- Ranking the customer's country by invoice_date DESC to get their latest country\n",
    "  FROM uvw_src_cleaned_df\n",
    ")\n",
    "\n",
    "SELECT DISTINCT\n",
    "  ROW_NUMBER() OVER (ORDER BY customer_id)      AS dim_customer_id\n",
    "  , customer_id\n",
    "  , country\n",
    "FROM ranked_customers_country\n",
    "WHERE rn = 1; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb9090d7-21a9-42be-b302-4ec418aa8044",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Merge into dim_customer"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "MERGE INTO dim_customer AS TGT\n",
    "USING customers_country AS SRC\n",
    "ON TGT.customer_id = SRC.customer_id          -- Merge on customer_id\n",
    "\n",
    "-- When matched on customer_id, and the other columns are not matching, then update the existing row\n",
    "WHEN MATCHED\n",
    "AND TGT.country <> SRC.country\n",
    "THEN UPDATE SET\n",
    "TGT.country = SRC.country\n",
    "\n",
    "-- When not matched on customer_id, insert the new row\n",
    "WHEN NOT MATCHED\n",
    "THEN INSERT *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d08db623-5a46-450e-a616-03e97acc5214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "  ROW_NUMBER() OVER (ORDER BY invoice_number, P.dim_product_id, C.dim_customer_id) AS fct_sale_id\n",
    "  , invoice_number\n",
    "  , P.dim_product_id\n",
    "  , C.dim_customer_id\n",
    "  , SUM(quantity)     AS total_quantity\n",
    "FROM uvw_src_cleaned_df SRCV\n",
    "LEFT JOIN dim_product AS P \n",
    "  ON SRCV.product_code = P.product_code\n",
    "LEFT JOIN dim_customer AS C\n",
    "  ON SRCV.customer_id = C.customer_id\n",
    "GROUP BY \n",
    "  invoice_number\n",
    "  , P.dim_product_id\n",
    "  , C.dim_customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6b8f489-eeac-4631-b99c-6a30d61ee460",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "fact_sale"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "WITH CTE_fact_sale AS (\n",
    "  SELECT DISTINCT                                -- Avoid duplicates\n",
    "    -- Distinct row number for every product in a invoice for a customer\n",
    "    ROW_NUMBER() OVER (ORDER BY invoice_number, P.dim_product_id, C.dim_customer_id) AS fct_sale_id                       \n",
    "    , invoice_number\n",
    "    , P.dim_product_id\n",
    "    , C.dim_customer_id\n",
    "    , MAX(invoice_date) AS invoice_date           -- Taking the latest invoice date for each invoice number\n",
    "    , SUM(quantity)     AS total_quantity\n",
    "  FROM uvw_src_cleaned_df SRCV\n",
    "  LEFT JOIN dim_product AS P \n",
    "    ON SRCV.product_code = P.product_code\n",
    "  LEFT JOIN dim_customer AS C\n",
    "    ON SRCV.customer_id = C.customer_id\n",
    "  GROUP BY                                       -- Grouping by invoice number, product and customer code as granularity is invoice by product by customer\n",
    "    invoice_number\n",
    "    , P.dim_product_id\n",
    "    , C.dim_customer_id\n",
    ")\n",
    "\n",
    "\n",
    "-- Merging on invoice number, product and customer code as granularity is invoice by product by customer\n",
    "MERGE INTO fact_sale AS TGT\n",
    "USING CTE_fact_sale AS SRC\n",
    "ON TGT.invoice_number = SRC.invoice_number      \n",
    "AND TGT.dim_product_id =  SRC.dim_product_id\n",
    "AND TGT.dim_customer_id =  SRC.dim_customer_id\n",
    "\n",
    "-- When matched on invoice, product, and customer, and the other columns are not matching, then update the existing row\n",
    "WHEN MATCHED\n",
    "AND TGT.invoice_date <> SRC.invoice_date\n",
    "AND TGT.total_quantity <> SRC.total_quantity\n",
    "THEN UPDATE SET \n",
    "TGT.invoice_date = SRC.invoice_date\n",
    ",TGT.total_quantity =  SRC.total_quantity\n",
    "\n",
    "-- When not matched on invoice, product, and customer, then insert the new row\n",
    "WHEN NOT MATCHED\n",
    "THEN INSERT *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7efd891-43d1-4cf1-a728-83a34aa4e60d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Optimize tables"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "OPTIMIZE dim_product\n",
    "ZORDER BY (product_code);     -- Optimizing on product_code as it is used often for filtering and joining\n",
    "\n",
    "OPTIMIZE dim_customer\n",
    "ZORDER BY (customer_id);\n",
    "\n",
    "OPTIMIZE fact_sale\n",
    "ZORDER BY (invoice_number);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54d4ae31-ae33-41cb-94fd-8341982d69b1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Quality check - dim_product"
    }
   },
   "outputs": [],
   "source": [
    "product_quality_check = spark.sql(\"\"\"SELECT product_code, COUNT(*) \n",
    "FROM dim_product\n",
    "GROUP BY product_code\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\")\n",
    "\n",
    "if product_quality_check.count() > 0:\n",
    "    raise Exception(\"Validation Error: Duplicate product code found in dim_product table.\")\n",
    "else:\n",
    "    print(\"No duplicates found in dim_product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aaffa96-d54d-4b47-b4eb-3d86af510e9c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Quality check - dim_customer"
    }
   },
   "outputs": [],
   "source": [
    "customer_quality_check = spark.sql(\"\"\"SELECT customer_id, COUNT(*) \n",
    "FROM dim_customer\n",
    "GROUP BY customer_id\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\")\n",
    "\n",
    "if customer_quality_check.count() > 0:\n",
    "    raise Exception(\"Validation Error: Duplicate customer id found in dim_customer table.\")\n",
    "else:\n",
    "    print(\"No duplicates found in dim_customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cda9916-a0dd-48f8-850c-52295cb970b0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Quality check - fact_sale"
    }
   },
   "outputs": [],
   "source": [
    "sale_quality_check = spark.sql(\"\"\"SELECT invoice_number, dim_product_id, dim_customer_id, COUNT(*) \n",
    "FROM fact_sale\n",
    "GROUP BY invoice_number, dim_product_id, dim_customer_id\n",
    "HAVING COUNT(*) > 1\"\"\")\n",
    "\n",
    "if sale_quality_check.count() > 0:\n",
    "    raise Exception(\"Validation Error: Duplicate sale transactions found in fact_sale table.\")\n",
    "else:\n",
    "    print(\"No duplicates found in fact_sale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95222a03-125b-4bef-a625-5a8b4bfc6f0d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Quality check - null products in fact_sale"
    }
   },
   "outputs": [],
   "source": [
    "null_product_check = spark.sql(\"\"\"SELECT * FROM fact_sale WHERE dim_product_id is NULL\"\"\")\n",
    "\n",
    "if null_product_check.count() > 0:\n",
    "    raise Exception(\"Validation Error: NULL values found in dim_product_id column of fact_sale table.\")\n",
    "else:\n",
    "    print(\"No null values found in dim_product_id column of fact_sale table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b0bdf33-07f3-4346-a3e3-57dbdcffbafc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Quality check - null customers in fact_sale"
    }
   },
   "outputs": [],
   "source": [
    "null_customer_check = spark.sql(\"\"\"SELECT * FROM fact_sale WHERE dim_customer_id is NULL\"\"\")\n",
    "\n",
    "if null_customer_check.count() > 0:\n",
    "    raise Exception(\"Validation Error: NULL values found in dim_customer_id column of fact_sale table.\")\n",
    "else:\n",
    "    print(\"No null values found in dim_customer_id column of fact_sale table.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04 - Create Warehouse",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
